// Re-import bills table from CSV to get all 1,784 records
const fs = require('fs');
const { createClient } = require('@supabase/supabase-js');
require('dotenv').config();

const supabase = createClient(
  process.env.SUPABASE_URL,
  process.env.SUPABASE_SERVICE_ROLE_KEY
);

function cleanColumnName(columnName) {
  return columnName
    .toLowerCase()
    .replace(/[^a-z0-9_]/g, '_')
    .replace(/_{2,}/g, '_')
    .replace(/^_|_$/g, '')
    .substring(0, 63);
}

function cleanHeaders(headers) {
  const cleanedHeaders = [];
  const seenNames = new Set();
  const headerMapping = {};
  
  headers.forEach(header => {
    let cleanName = cleanColumnName(header);
    
    let finalName = cleanName;
    let counter = 1;
    while (seenNames.has(finalName)) {
      finalName = `${cleanName}_${counter}`;
      counter++;
    }
    
    seenNames.add(finalName);
    cleanedHeaders.push(finalName);
    headerMapping[header] = finalName;
  });
  
  return { cleanedHeaders, headerMapping };
}

function parseCSV(content) {
  const lines = content.split('\n').filter(line => line.trim());
  
  // Parse header line manually to handle quoted fields
  const headerLine = lines[0];
  const headerMatches = headerLine.match(/(?:^|,)("(?:[^"]+|"")*"|[^,]*)/g);
  const headers = headerMatches.map(match => 
    match.replace(/^,/, '').replace(/^"|"$/g, '')
  );
  
  const { cleanedHeaders, headerMapping } = cleanHeaders(headers);
  console.log(`üìã Headers: ${headers.length} columns`);
  
  const rows = [];
  
  // Parse data lines with proper CSV handling
  for (let i = 1; i < lines.length; i++) {
    const line = lines[i];
    const matches = line.match(/(?:^|,)("(?:[^"]+|"")*"|[^,]*)/g);
    
    if (matches && matches.length === headers.length) {
      const values = matches.map(match => 
        match.replace(/^,/, '').replace(/^"|"$/g, '').trim()
      );
      
      const row = {};
      headers.forEach((header, index) => {
        const cleanKey = headerMapping[header];
        let value = values[index];
        
        // Handle empty values
        if (value === '' || value === null || value === undefined) {
          value = null;
        } else if (typeof value === 'string') {
          value = value.trim();
          // Remove carriage returns that might cause issues
          value = value.replace(/\r/g, '');
        }
        
        row[cleanKey] = value;
      });
      rows.push(row);
    } else {
      console.warn(`‚ö†Ô∏è  Line ${i + 1}: Column mismatch - expected ${headers.length}, got ${matches ? matches.length : 0}`);
    }
  }
  
  return { rows, headerMapping, totalColumns: headers.length };
}

async function reimportBills() {
  try {
    console.log('üöÄ RE-IMPORTING BILLS FROM CSV');
    console.log('='.repeat(50));
    console.log(`üïê Started at: ${new Date().toISOString()}\n`);
    
    // 1. Read and parse CSV
    console.log('üìÑ Reading bills CSV...');
    const csvPath = './exports/bills_2025-07-25.csv';
    const content = fs.readFileSync(csvPath, 'utf8');
    const { rows, headerMapping } = parseCSV(content);
    
    console.log(`‚úÖ Parsed ${rows.length} rows from CSV`);
    
    // 2. Create fresh table schema
    console.log('\nüîß Creating fresh table schema...');
    const columns = Object.values(headerMapping).map(col => `${col} TEXT`).join(', ');
    
    const createSQL = `
      DROP TABLE IF EXISTS bills CASCADE;
      CREATE TABLE bills (
        id SERIAL PRIMARY KEY,
        ${columns},
        created_at TIMESTAMP DEFAULT NOW(),
        updated_at TIMESTAMP DEFAULT NOW()
      );
      CREATE INDEX IF NOT EXISTS bills_created_at_idx ON bills (created_at);
      CREATE INDEX IF NOT EXISTS bills_bill_date_idx ON bills (bill_date);
      CREATE INDEX IF NOT EXISTS bills_vendor_id_idx ON bills (vendor_id);
    `;
    
    const { error: createError } = await supabase.rpc('exec_sql', { sql_text: createSQL });
    
    if (createError) {
      console.error('‚ùå Failed to create table:', createError.message);
      return;
    }
    
    console.log('‚úÖ Table created successfully');
    
    // 3. Import data in optimized batches
    console.log('\nüì• Importing data in batches...');
    const batchSize = 500; // Smaller batches for reliability
    let totalInserted = 0;
    const totalBatches = Math.ceil(rows.length / batchSize);
    
    for (let i = 0; i < rows.length; i += batchSize) {
      const batch = rows.slice(i, i + batchSize);
      const batchNum = Math.floor(i / batchSize) + 1;
      
      process.stdout.write(`üì¶ Batch ${batchNum}/${totalBatches} (${batch.length} records)... `);
      
      const { data, error } = await supabase
        .from('bills')
        .insert(batch);
      
      if (error) {
        console.error(`\n‚ùå Batch ${batchNum} failed:`, error.message);
        console.error('Sample row:', JSON.stringify(batch[0], null, 2));
        break;
      }
      
      totalInserted += batch.length;
      console.log(`‚úÖ`);
      
      // Progress update every 10 batches
      if (batchNum % 10 === 0) {
        const progress = ((totalInserted / rows.length) * 100).toFixed(1);
        console.log(`   üìä Progress: ${totalInserted.toLocaleString()}/${rows.length.toLocaleString()} (${progress}%)`);
      }
    }
    
    // 4. Verify import
    console.log('\nüîç Verifying import...');
    const { count, error: countError } = await supabase
      .from('bills')
      .select('*', { count: 'exact', head: true });
    
    if (countError) {
      console.error('‚ùå Verification failed:', countError.message);
    } else {
      console.log(`‚úÖ Verification: ${count} bills in database`);
    }
    
    // 5. Check high-value bills specifically
    const { count: highValueCount, error: highValueError } = await supabase
      .from('bills')
      .select('*', { count: 'exact', head: true })
      .like('balance_bcy', '%,%');
    
    if (!highValueError) {
      console.log(`üí∞ High-value bills (with commas): ${highValueCount}`);
    }
    
    console.log('\n' + '='.repeat(50));
    console.log('üìä IMPORT SUMMARY');
    console.log('='.repeat(50));
    console.log(`‚úÖ CSV rows parsed: ${rows.length}`);
    console.log(`‚úÖ Database rows: ${count || 'Error checking'}`);
    console.log(`‚úÖ High-value bills: ${highValueCount || 'Error checking'}`);
    console.log(`üïê Completed at: ${new Date().toISOString()}`);
    
    return {
      success: true,
      csvRows: rows.length,
      dbRows: count,
      highValueBills: highValueCount
    };
    
  } catch (error) {
    console.error('‚ùå Import failed:', error.message);
    return { success: false, error: error.message };
  }
}

if (require.main === module) {
  reimportBills()
    .then(result => {
      if (result.success) {
        console.log('\nüéâ BILLS RE-IMPORT COMPLETED SUCCESSFULLY!');
        process.exit(0);
      } else {
        console.log('\nüí• BILLS RE-IMPORT FAILED:', result.error);
        process.exit(1);
      }
    })
    .catch(error => {
      console.error('üí• Import crashed:', error.message);
      process.exit(1);
    });
}